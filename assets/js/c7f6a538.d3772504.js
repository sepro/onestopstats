"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[981],{3905:(e,t,n)=>{n.d(t,{Zo:()=>l,kt:()=>f});var r=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,r,o=function(e,t){if(null==e)return{};var n,r,o={},a=Object.keys(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var c=r.createContext({}),u=function(e){var t=r.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},l=function(e){var t=u(e.components);return r.createElement(c.Provider,{value:t},e.children)},p="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var n=e.components,o=e.mdxType,a=e.originalType,c=e.parentName,l=i(e,["components","mdxType","originalType","parentName"]),p=u(n),m=o,f=p["".concat(c,".").concat(m)]||p[m]||d[m]||a;return n?r.createElement(f,s(s({ref:t},l),{},{components:n})):r.createElement(f,s({ref:t},l))}));function f(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=n.length,s=new Array(a);s[0]=m;var i={};for(var c in t)hasOwnProperty.call(t,c)&&(i[c]=t[c]);i.originalType=e,i[p]="string"==typeof e?e:o,s[1]=i;for(var u=2;u<a;u++)s[u]=n[u];return r.createElement.apply(null,s)}return r.createElement.apply(null,n)}m.displayName="MDXCreateElement"},715:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>d,frontMatter:()=>a,metadata:()=>i,toc:()=>u});var r=n(7462),o=(n(7294),n(3905));const a={sidebar_position:3},s="Autoencoder",i={unversionedId:"neural_networks/autoencoder",id:"neural_networks/autoencoder",title:"Autoencoder",description:"An autoencoder is a type of neural network that is trained to compress and decompress data. It consists of an encoder that compresses the input data into a lower-dimensional representation, and a decoder that reconstructs the original data from the compressed representation. The goal of an autoencoder is to learn a compressed representation that captures the most important features of the input data, while minimizing the reconstruction error.",source:"@site/docs/neural_networks/autoencoder.md",sourceDirName:"neural_networks",slug:"/neural_networks/autoencoder",permalink:"/onestopstats/docs/neural_networks/autoencoder",draft:!1,editUrl:"https://github.com/sepro/onestopstats/blob/main/docs/neural_networks/autoencoder.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Neural Networks",permalink:"/onestopstats/docs/category/neural-networks"}},c={},u=[{value:"Use Cases",id:"use-cases",level:2},{value:"Conclusion",id:"conclusion",level:2}],l={toc:u},p="wrapper";function d(e){let{components:t,...n}=e;return(0,o.kt)(p,(0,r.Z)({},l,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"autoencoder"},"Autoencoder"),(0,o.kt)("p",null,"An autoencoder is a type of neural network that is trained to compress and decompress data. It consists of an encoder that compresses the input data into a lower-dimensional representation, and a decoder that reconstructs the original data from the compressed representation. The goal of an autoencoder is to learn a compressed representation that captures the most important features of the input data, while minimizing the reconstruction error."),(0,o.kt)("h2",{id:"use-cases"},"Use Cases"),(0,o.kt)("p",null,"Autoencoders are a type of neural network that can be broadly used in various fields such as computer vision, natural language processing, speech recognition, and anomaly detection. They have been used effectively for tasks such as image and video compression, feature extraction, dimensionality reduction, and generating realistic images or text. With the increasing use of deep learning in various industries, autoencoders have become a popular method for unsupervised learning and have shown promising results in a wide range of applications."),(0,o.kt)("h2",{id:"conclusion"},"Conclusion"),(0,o.kt)("p",null," Autoencoders have become an important tool in deep learning, providing a powerful method for unsupervised learning and data compression. With their ability to extract meaningful features from complex data, autoencoders have shown great potential for solving a wide range of problems in various fields. As deep learning continues to advance, we can expect to see even more exciting applications of autoencoders and other neural networks in the future."))}d.isMDXComponent=!0}}]);