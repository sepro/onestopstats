"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[11],{3905:(e,t,s)=>{s.d(t,{Zo:()=>p,kt:()=>f});var n=s(7294);function r(e,t,s){return t in e?Object.defineProperty(e,t,{value:s,enumerable:!0,configurable:!0,writable:!0}):e[t]=s,e}function i(e,t){var s=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),s.push.apply(s,n)}return s}function o(e){for(var t=1;t<arguments.length;t++){var s=null!=arguments[t]?arguments[t]:{};t%2?i(Object(s),!0).forEach((function(t){r(e,t,s[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(s)):i(Object(s)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(s,t))}))}return e}function a(e,t){if(null==e)return{};var s,n,r=function(e,t){if(null==e)return{};var s,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)s=i[n],t.indexOf(s)>=0||(r[s]=e[s]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)s=i[n],t.indexOf(s)>=0||Object.prototype.propertyIsEnumerable.call(e,s)&&(r[s]=e[s])}return r}var l=n.createContext({}),c=function(e){var t=n.useContext(l),s=t;return e&&(s="function"==typeof e?e(t):o(o({},t),e)),s},p=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},h="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},y=n.forwardRef((function(e,t){var s=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,p=a(e,["components","mdxType","originalType","parentName"]),h=c(s),y=r,f=h["".concat(l,".").concat(y)]||h[y]||u[y]||i;return s?n.createElement(f,o(o({ref:t},p),{},{components:s})):n.createElement(f,o({ref:t},p))}));function f(e,t){var s=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=s.length,o=new Array(i);o[0]=y;var a={};for(var l in t)hasOwnProperty.call(t,l)&&(a[l]=t[l]);a.originalType=e,a[h]="string"==typeof e?e:r,o[1]=a;for(var c=2;c<i;c++)o[c]=s[c];return n.createElement.apply(null,o)}return n.createElement.apply(null,s)}y.displayName="MDXCreateElement"},1984:(e,t,s)=>{s.r(t),s.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>i,metadata:()=>a,toc:()=>c});var n=s(7462),r=(s(7294),s(3905));const i={sidebar_position:4},o="False Discovery Rate (FDR)",a={unversionedId:"hypothesis_testing/multiple_hypothesis_correction/fdr",id:"hypothesis_testing/multiple_hypothesis_correction/fdr",title:"False Discovery Rate (FDR)",description:"False Discovery Rate (FDR) is a statistical method that is used to control the number of false positives when testing multiple hypotheses simultaneously. In simple terms, it helps to control the rate at which we falsely identify something as significant when it is actually not.",source:"@site/docs/hypothesis_testing/multiple_hypothesis_correction/fdr.md",sourceDirName:"hypothesis_testing/multiple_hypothesis_correction",slug:"/hypothesis_testing/multiple_hypothesis_correction/fdr",permalink:"/onestopstats/docs/hypothesis_testing/multiple_hypothesis_correction/fdr",draft:!1,editUrl:"https://github.com/sepro/onestopstats/blob/main/docs/hypothesis_testing/multiple_hypothesis_correction/fdr.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4},sidebar:"tutorialSidebar",previous:{title:"Multiple Hypothesis Correcton",permalink:"/onestopstats/docs/category/multiple-hypothesis-correcton"},next:{title:"Student's t-test",permalink:"/onestopstats/docs/hypothesis_testing/t_test"}},l={},c=[{value:"Use Cases",id:"use-cases",level:2}],p={toc:c},h="wrapper";function u(e){let{components:t,...s}=e;return(0,r.kt)(h,(0,n.Z)({},p,s,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"false-discovery-rate-fdr"},"False Discovery Rate (FDR)"),(0,r.kt)("p",null,"False Discovery Rate (FDR) is a statistical method that is used to control the number of false positives when testing multiple hypotheses simultaneously. In simple terms, it helps to control the rate at which we falsely identify something as significant when it is actually not. "),(0,r.kt)("p",null,"For instance, if we are testing several hypotheses at once, we might find some results that look significant by chance but are actually not. FDR helps to reduce the chances of reporting these false positives. "),(0,r.kt)("h2",{id:"use-cases"},"Use Cases"),(0,r.kt)("p",null,"Let's say a group of researchers is testing a new drug for a disease. They conduct a study with 100 patients and measure the effect of the drug on 100 different genes. "),(0,r.kt)("p",null,"If they test each gene independently with a significance level of 0.05, they would expect to see 5 false positives (i.e., genes that appear significant by chance). However, if they use FDR control, they can adjust the significance level for each gene, so that the overall rate of false positives is controlled at, say, 5%. This means that out of the 100 genes tested, they would expect to see 5 genes that are falsely identified as significant. "),(0,r.kt)("p",null,"By using FDR control, the researchers can ensure that they are only reporting significant results that are likely to be true and not accidentally claiming that the drug works when it actually does not."))}u.isMDXComponent=!0}}]);